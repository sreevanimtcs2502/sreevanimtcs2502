{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsPqy0jsIdLPXKUH9RE1Ww",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreevanimtcs2502/sreevanimtcs2502/blob/main/ngram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "POE_URLS = [\n",
        "    \"https://www.gutenberg.org/files/2147/2147-0.txt\",\n",
        "    \"https://www.gutenberg.org/files/2148/2148-0.txt\",\n",
        "    \"https://www.gutenberg.org/files/2149/2149-0.txt\"\n",
        "]\n",
        "\n",
        "def load_gutenberg_corpus(urls):\n",
        "    texts = []\n",
        "    for url in urls:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        texts.append(response.text)\n",
        "    return \"\\n\".join(texts)\n",
        "\n",
        "def clean_gutenberg_text(text):\n",
        "    start = re.search(r\"\\*\\*\\* START OF.*?\\*\\*\\*\", text, re.IGNORECASE)\n",
        "    end = re.search(r\"\\*\\*\\* END OF.*?\\*\\*\\*\", text, re.IGNORECASE)\n",
        "    if start and end:\n",
        "        text = text[start.end():end.start()]\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "def tokenize(text):\n",
        "    return text.split()\n",
        "\n",
        "class NGramLanguageModel:\n",
        "    def __init__(self, n):\n",
        "        self.n = n\n",
        "        self.ngram_counts = defaultdict(Counter)\n",
        "        self.context_counts = Counter()\n",
        "        self.vocab = set()\n",
        "\n",
        "    def train(self, tokens):\n",
        "        for i in range(len(tokens) - self.n + 1):\n",
        "            context = tuple(tokens[i:i+self.n-1])\n",
        "            target = tokens[i+self.n-1]\n",
        "            self.ngram_counts[context][target] += 1\n",
        "            self.context_counts[context] += 1\n",
        "            self.vocab.add(target)\n",
        "\n",
        "    def next_word_distribution(self, context):\n",
        "        vocab_size = len(self.vocab)\n",
        "        total = self.context_counts[context] + vocab_size\n",
        "        words, probs = [], []\n",
        "        for word in self.vocab:\n",
        "            count = self.ngram_counts[context][word]\n",
        "            words.append(word)\n",
        "            probs.append((count + 1) / total)\n",
        "        return words, probs\n",
        "\n",
        "    def generate(self, seed_text, max_len=40):\n",
        "        seed_tokens = seed_text.lower().split()\n",
        "        if len(seed_tokens) < self.n - 1:\n",
        "            raise ValueError(\"Seed text must contain at least 4 words\")\n",
        "        generated = seed_tokens[:]\n",
        "        for _ in range(max_len):\n",
        "            context = tuple(generated[-(self.n-1):])\n",
        "            words, probs = self.next_word_distribution(context)\n",
        "            generated.append(random.choices(words, probs)[0])\n",
        "        return \" \".join(generated)\n",
        "\n",
        "raw_text = load_gutenberg_corpus(POE_URLS)\n",
        "clean_text = clean_gutenberg_text(raw_text)\n",
        "tokens = tokenize(clean_text)\n",
        "\n",
        "model = NGramLanguageModel(n=5)\n",
        "model.train(tokens)\n",
        "\n",
        "samples = [\n",
        "    \"the day was very\",\n",
        "    \"i felt a strange\",\n",
        "    \"there was something about the \"\n",
        "]\n",
        "\n",
        "for prompt in samples:\n",
        "    print(\"Input :\", prompt)\n",
        "    print(\"Output:\", model.generate(prompt))\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6HTWlSXJsCe",
        "outputId": "58eb1806-4109-4ddd-a784-2a969a9213e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : the day was very\n",
            "Output: the day was very beamends absolutely reap demonstrated messieurs alternative locked topics inclined internally nom thronged wager repetition massade punch crowbar streaks burial alland profounder astonishing modes accomplished lui wormeaten volume two delicate arm touch gnarled delicate suspicious paralleling discharge orthographically bleeding snugly collation\n",
            "\n",
            "Input : i felt a strange\n",
            "Output: i felt a strange sense furnishing wicker wondering concerned enckes mercurie quondam bags artizan non dreaming trusted lanterns highway listen changeless seemingly survives expressive gown advanced enthusiasm wiser daybreak personalities sinks notorious carryingmore method resign solitudes antagonistic with sitting sulky jourdains odd revenue impunity\n",
            "\n",
            "Input : there was something about the \n",
            "Output: there was something about the shrivelled identical mystic earnest hating editions comprehended quinaultatys rapid meeting treated ruffles skies herein room broke scheme expediency onethat questions modulated greatest morewould attended reading indistinctly filigreed employment food seating wasted controlling miraculous projections judgment pope locked glasshouse discard lenticularshaped\n",
            "\n"
          ]
        }
      ]
    }
  ]
}